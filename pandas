2877. Create a DataFrame from List

import pandas as pd

def createDataframe(student_data: List[List[int]]):
    columns = ['student_id', 'age']
    df = pd.DataFrame(student_data, columns = columns)
    return df


-- 262. Trips and Users

with a as(
select t. id, t.client_id, t.driver_id, t.city_id, t.status, t.request_at    
from Trips as t
left join users as u
on t.client_id = u.users_id 
left join users as u1
on t.driver_id = u1.users_id 
where u.banned = 'No' and u1.banned = 'No')

select request_at as Day,
round(sum(if(status='completed', 0, 1))/count(status),2) as 'Cancellation Rate'
from a
where request_at between '2013-10-01' and '2013-10-03'
group by request_at

-- another way

select request_at as Day,
round(sum(if(status='completed', 0, 1))/count(status),2) as 'Cancellation Rate'
from Trips
where request_at between '2013-10-01' and '2013-10-03'
and client_id not in (select client_id from Trips as t left join users as u on t. client_id = u. users_id where u.banned = 'Yes')
and driver_id not in (select driver_id from Trips as t left join users as u on t. driver_id = u. users_id where u.banned = 'Yes')
group by request_at

-- simplier way: since we already know the users fields are matching

select request_at as Day,
round(sum(if(status='completed', 0, 1))/count(status),2) as 'Cancellation Rate'
from Trips
where request_at between '2013-10-01' and '2013-10-03'
and client_id not in (select users_id from users where banned = 'Yes')
and driver_id not in (select users_id from users where banned = 'Yes')
group by request_at


-- 601. Human Traffic of Stadium
-- use where first, id - row_number() is consecutive number of people > 100
-- be aware consecutive is consecutive id, not vistit date 

with a as(select *,  id - row_number()over(order by id asc) as rnk
from stadium
where people>=100)

select id, visit_date, people
from a
where rnk in (select rnk from a group by rnk having count(rnk)>=3)

--570. Managers with at Least 5 Direct Reports: notice! id in, not managerId in ()

select name
from Employee
where id in
(select managerId from Employee group by managerId having  count(managerId) >= 5)

-- pandas
import pandas as pd
def find_managers(employee: pd.DataFrame) -> pd.DataFrame:
    # add a new column called count
    managers = employee.groupby(['managerId'])['managerId'].agg(['count']).reset_index()
    managers = managers.loc[managers['count']>= 5, ['managerId']]
    new_df = employee.loc[employee['id'].isin(managers['managerId']), ['name']]
    # new_df = employee[employee['id'].isin(managers['managerId'])][['name']]
    return new_df

-- 1934. Confirmation Rate
--  mean = sum/count can also be replaced into: round(avg(if(c.action="confirmed",1,0)),2)

select s.user_id, round(sum(if(c.action= 'confirmed', 1,0))/count(s.user_id),2) as confirmation_rate
from Signups as s
left join Confirmations as c
on s.user_id = c.user_id
group by s.user_id

pandas: need to reste_index after group by

    confirmations['confirmation_rate'] = confirmations['action'].apply(lambda x:1 if x == 'confirmed' else 0)
    avg_conf = confirmations[['user_id','confirmation_rate']].groupby('user_id')['confirmation_rate'].mean().round(2).reset_index()
    output = pd.merge(signups['user_id'],avg_conf,how='left').fillna(0)  
    return output

-- 1193. Monthly Transactions I
-- can also use: DATE_FORMAT(trans_date, '%Y-%m')

select left(trans_date, 7) as month, country,
count(id) as trans_count,
sum(if(state ='approved', 1, 0)) as approved_count,
sum(amount) as trans_total_amount,
sum(if(state ='approved', amount, 0)) as approved_total_amount
from Transactions
group by left(trans_date, 7), country

pandas:

def monthly_transactions(transactions: pd.DataFrame) -> pd.DataFrame:
    transactions['month'] = transactions.apply(lambda x: x['trans_date'].strftime("%Y-%m"), axis=1)
    # why cannot 0, must be? since we will use approved_count below, count a column will include 0, if we set to null, null won't be included 
    transactions['approved_amount'] = transactions.apply(lambda x: x['amount'] if x['state'] == 'approved' else np.nan, axis =1 ) 
    # we we need dropna here, since we wil have NULL contry in the test section, we want keep it as null in the amount summary
    return transactions.groupby(['month','country'],as_index=False,dropna=False).agg(
                            trans_count=('id', 'count'),                            
                            approved_count=('approved_amount', 'count'),
                            trans_total_amount=('amount', 'sum'),
                            approved_total_amount=('approved_amount', 'sum')
                            )


1174. Immediate Food Delivery II (note: cannot use min(date) at first, then count, those steps will mismatch min(date) to order date (first show date), will reduce the count of (daye same) 

select round(100*sum(if(order_date = customer_pref_delivery_date, 1,0))/count(distinct customer_id),2) as immediate_percentage
from Delivery
where (customer_id, order_date)
in (select customer_id, min(order_date) as min_date
from Delivery group by customer_id )


550. Game Play Analysis IV
-- use IN
with a as(select player_id, min(event_date) as min_date
from Activity 
group by player_id)

select round(count(a1.player_id)/(select count(distinct player_id) from Activity),2) as fraction
from Activity as a1
inner join a as a2 
on a1.player_id = a2.player_id
where DATEDIFF(a1.event_date, a2.min_date) =1
and (a2.min_date, a1.player_id) 
in (select min(event_date), player_id from Activity group by player_id)

-- use sumif, replace first line

select round(sum(if(datediff(a.event_date, b.first_date)=1,1,0))/count(distinct a.player_id),2) as fraction


-- another way, I don't want to use join, since I DON'T know left or right one has min date,
-- which one is min day, so use date_sub, a day could smaller than day -1 or large than day +1
SELECT ROUND(COUNT(DISTINCT player_id) / (SELECT COUNT(DISTINCT player_id) FROM Activity), 2) as fraction
FROM Activity
WHERE (player_id, DATE_SUB(event_date, INTERVAL 1 DAY))
IN (SELECT player_id, MIN(event_date) AS first_login FROM ACTIVITY GROUP BY player_id)

--1070. Product Sales Analysis III

select p.product_id, s.year as first_year, s.quantity, s.price
from Product as p
left join Sales as s
on p.product_id = s.product_id
where (s.year, p.product_id) in
(select min(year), product_id from Sales group by product_id)

--1045. Customers Who Bought All Products

select customer_id
from Customer
group by customer_id
having count(distinct product_key)  = (select count(distinct product_key) from Product)

pandas:
import pandas as pd

def find_customers(customer: pd.DataFrame, product: pd.DataFrame) -> pd.DataFrame:
    df = customer.drop_duplicates(keep = 'first').groupby('customer_id').count().reset_index()
    new_df = df[df['product_key'] == len(product)][['customer_id']]
    return new_df

-- 180. Consecutive Numbers (cannot use lag(), and lead() since the id is consecutive)

-- method 1: left join
-- be aware to use distinct, since if num 3 happens 4 times, it produce 2 times 4 

select distinct l1.num as ConsecutiveNums
from logs as l1
left join logs as l2
on l1.id = l2.id -1
left join logs as l3
on l2.id = l3.id -1
where l1.num = l2.num and l2.num = l3.num

method 2: self join
select distinct l1.num as ConsecutiveNums
from logs as l1, logs as l2, logs as l3
where l1.id = l2.id-1 and l2.id = l3.id -1 and l1.num = l2.num and l2.num = l3.num

-- 1164. Product Price at a Given Date

-- price before 2019-08-16 step1: pick the max date <= that day, meaning some price missiing will be 10, use left join to fill the missing price as 10

with a as(select product_id, new_price,
dense_rank() over(partition by product_id order by change_date desc) as rnk
from Products
where change_date <= '2019-08-16'), b as (select product_id, new_price
from a
where rnk = 1)


select p.product_id, 
ifnull(b.new_price, 10) as price
from Products as p
left join b 
on b.product_id = p.product_id
group by product_id

-- 1204. Last Person to Fit in the Bus

with a as(select person_id,  person_name,
sum(weight) over(order by turn) as total_weight
from Queue), b as(select person_name, rank() over(order by total_weight desc) as rnk
from a
where total_weight <= 1000)

select person_name
from b
where rnk = 1

--1907. Count Salary Categories

select 'Low Salary' as category,
sum(if(income < 20000,1,0)) as accounts_count
from Accounts
union 
select 'Average Salary' as category,
sum(if(income >= 20000 and income <= 50000 ,1,0)) as accounts_count
from Accounts
union
select 'High Salary' as category,
sum(if(income > 50000,1,0)) as accounts_count
from Accounts

-- 626. Exchange Seats: be aware that id= (select max(id) from Seat)  not id = max(id) since id column is not original id column, it's changing
select 
case 
when id%2 =1 and id= (select max(id) from Seat) then id
when id%2 =1 then id+1
else  id-1 end as id,
student
from Seat
order by id

-- 1341. Movie Rating -- remember use union all, to keep duplciate, since person and movie name could be same 

(select u.name as results
from MovieRating as m
left join users as u
on m.user_id = u.user_id
group by m.user_id
order by count(distinct movie_id) desc, u.name
limit 1)
union all
(select v.title
from MovieRating as m
left join Movies as v
on m.movie_id = v.movie_id
where date_format(m.created_at, '%Y-%m') = '2020-02'
group by m.movie_id
order by avg(m.rating) desc, v.title
limit 1)

